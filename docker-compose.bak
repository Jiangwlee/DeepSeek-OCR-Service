version: "3.9"

services:
  minio:
    image: minio/minio:RELEASE.2024-12-18T13-15-44Z
    container_name: ${COMPOSE_PROJECT_NAME:-deepseek-ocr}-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION}
      NO_PROXY: ${NO_PROXY}
      no_proxy: ${NO_PROXY}
    volumes:
      - ${MINIO_DATA_DIR:-./.data/minio/data}:/data
      - ${MINIO_CONFIG_DIR:-./.data/minio/config}:/root/.minio
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - deepseek-internal

  document-converter:
    build:
      context: .
      dockerfile: services/document-converter/Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-deepseek-ocr}-doc-converter
    restart: unless-stopped
    environment:
      MINIO_ENDPOINT: ${MINIO_ENDPOINT:-minio:9000}
      MINIO_SECURE: ${MINIO_SECURE:-false}
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      NO_PROXY: ${NO_PROXY}
      no_proxy: ${NO_PROXY}
    depends_on:
      minio:
        condition: service_started
    ports:
      - "${DOC_CONVERTER_PORT:-8002}:8000"
    networks:
      - deepseek-internal

  minio-init:
    image: minio/mc:RELEASE.2024-11-21T17-21-54Z
    depends_on:
      minio:
        condition: service_started
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_BUCKETS: ${MINIO_BUCKETS}
      MINIO_PUBLIC_BUCKET: ${MINIO_PUBLIC_BUCKET:-}
      NO_PROXY: ${NO_PROXY}
      no_proxy: ${NO_PROXY}
    entrypoint: ["/bin/sh"]
    command:
      - -c
      - |
        set -euo pipefail
        until mc alias set deepseek http://minio:9000 "${MINIO_ROOT_USER}" "${MINIO_ROOT_PASSWORD}"; do
          echo "Waiting for MinIO to become reachable..."
          sleep 3
        done
        for bucket in $(echo "${MINIO_BUCKETS}" | tr ',' ' '); do
          if [ -z "$${bucket}" ]; then
            continue
          fi
          mc mb --ignore-existing deepseek/$${bucket}
        done
        if [ -n "${MINIO_PUBLIC_BUCKET}" ]; then
          mc anonymous set download deepseek/${MINIO_PUBLIC_BUCKET}
        fi
        echo "MinIO buckets ready: ${MINIO_BUCKETS}"
    restart: "no"
    networks:
      - deepseek-internal

  ocr:
    build:
      context: .
      dockerfile: services/ocr/Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-deepseek-ocr}-ocr
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/docs/"]
      interval: 30s
      timeout: 20s
      retries: 3
    environment:
      OCR_VLLM_API_BASE: ${OCR_VLLM_API_BASE:-http://vllm-service:8000/v1}
      OCR_VLLM_API_KEY: ${OCR_VLLM_API_KEY:-EMPTY}
      OCR_VLLM_MODEL: ${OCR_VLLM_MODEL:-deepseek-ai/DeepSeek-OCR}
      OCR_VLLM_REQUEST_TIMEOUT: ${OCR_VLLM_REQUEST_TIMEOUT:-3600}
      OCR_VLLM_MAX_TOKENS: ${OCR_VLLM_MAX_TOKENS:-2048}
      OCR_VLLM_TEMPERATURE: ${OCR_VLLM_TEMPERATURE:-0.0}
      OCR_VLLM_SKIP_SPECIAL_TOKENS: ${OCR_VLLM_SKIP_SPECIAL_TOKENS:-false}
      OCR_PDF_DPI: ${OCR_PDF_DPI:-144}
      OCR_MAX_WORKERS: ${OCR_MAX_WORKERS:-4}
      OCR_MINIO_ENABLED: ${OCR_MINIO_ENABLED:-true}
      OCR_MINIO_ENDPOINT: ${OCR_MINIO_ENDPOINT:-http://minio:9000}
      OCR_MINIO_ACCESS_KEY: ${OCR_MINIO_ACCESS_KEY:-deepseekadmin}
      OCR_MINIO_SECRET_KEY: ${OCR_MINIO_SECRET_KEY:-deepseeksecret}
      OCR_MINIO_SECURE: ${OCR_MINIO_SECURE:-false}
      OCR_MINIO_DEFAULT_BUCKET: ${OCR_MINIO_DEFAULT_BUCKET:-ocr-results}
      OCR_PERSIST_RESULTS_BY_DEFAULT: ${OCR_PERSIST_RESULTS_BY_DEFAULT:-false}
      OCR_PADDLE_ENDPOINT: ${OCR_PADDLE_ENDPOINT:-http://paddle-ocr:9000}
      OCR_PADDLE_TIMEOUT: ${OCR_PADDLE_TIMEOUT:-60}
      HTTP_PROXY: ""
      HTTPS_PROXY: ""
      http_proxy: ""
      https_proxy: ""
      NO_PROXY: minio,minio-init,vllm-service,paddle-ocr,ocr,document-converter,bcebos.com,localhost,127.0.0.1,172.30.0.0/16
      no_proxy: minio,minio-init,vllm-service,paddle-ocr,ocr,document-converter,bcebos.com,localhost,127.0.0.1,172.30.0.0/16
    ports:
      - "${OCR_HTTP_PORT:-8001}:8001"
    depends_on:
      minio:
        condition: service_started
      vllm-service:
        condition: service_started
    networks:
      - deepseek-internal

  paddle-ocr:
    build:
      context: .
      dockerfile: services/paddle-ocr/Dockerfile
      args:
        BASE_IMAGE: ${PADDLE_BASE_IMAGE:-paddlepaddle/paddle:3.2.2-gpu-cuda12.6-cudnn9.5}
        REQUIREMENTS_FILE: services/paddle-ocr/requirements.gpu.txt
    container_name: ${COMPOSE_PROJECT_NAME:-deepseek-ocr}-paddle
    restart: unless-stopped
    shm_size: 8G
    gpus: all
    environment:
      PADDLE_LANG: ${PADDLE_LANG:-ch}
      PADDLE_USE_GPU: "true"
      CUDA_VISIBLE_DEVICES: "0"
      NVIDIA_VISIBLE_DEVICES: "all"
      NO_PROXY: ${NO_PROXY}
      no_proxy: ${NO_PROXY}
    volumes:
      - .cache/paddle_cache/.paddlex:/root/.paddlex
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/docs/"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - deepseek-internal

  vllm-service:
    build:
      context: .
      dockerfile: services/vllm-service/Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-deepseek-ocr}-vllm
    restart: unless-stopped
    environment:
      # Model configuration
      MODEL_NAME: ${VLLM_MODEL_NAME:-deepseek-ai/DeepSeek-OCR}
      MODEL_TYPE: ${VLLM_MODEL_TYPE:-auto}
      # vLLM server settings
      VLLM_HOST: ${VLLM_HOST:-0.0.0.0}
      VLLM_PORT: ${VLLM_PORT:-8000}
      # GPU and performance settings
      GPU_MEMORY_UTILIZATION: ${VLLM_GPU_MEMORY_UTILIZATION:-0.6}
      MAX_NUM_SEQS: ${VLLM_MAX_NUM_SEQS:-16}
      MAX_MODEL_LEN: ${VLLM_MAX_MODEL_LEN:-4096}
      MM_PROCESSOR_CACHE_GB: ${VLLM_MM_PROCESSOR_CACHE_GB:-0}
      # Optional advanced settings
      TENSOR_PARALLEL_SIZE: ${VLLM_TENSOR_PARALLEL_SIZE:-}
      LIMIT_VIDEO_INPUTS: ${VLLM_LIMIT_VIDEO_INPUTS:-}
      ENABLE_ASYNC_SCHEDULING: ${VLLM_ENABLE_ASYNC_SCHEDULING:-false}
      EXTRA_VLLM_ARGS: ${VLLM_EXTRA_VLLM_ARGS:-}
      # System settings
      CUDA_VISIBLE_DEVICES: ${VLLM_CUDA_VISIBLE_DEVICES:-0}
      VLLM_USE_MODELSCOPE: ${VLLM_USE_MODELSCOPE:-True}
      NO_PROXY: ${NO_PROXY}
      no_proxy: ${NO_PROXY}
    volumes:
      - ~/.cache/modelscope:/root/.cache/modelscope
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "${VLLM_PORT:-8003}:8003"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - deepseek-internal

networks:
  deepseek-internal:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/24
          gateway: 172.30.0.1
